<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>YAKL: YAKL: Yet Another Kernel Launcher</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">YAKL
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">YAKL: Yet Another Kernel Launcher </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>A Minimally Invasive C++ Performance Portability Library</h2>
<p>YAKL is designed to be similar to Kokkos but significantly simplified to make it easier to add new hardware backends quickly. The YAKL kernel launcher, <code>parallel_for</code>, will work on any object that can be validly accessed in GPU memory. This includes objects that were allocated in GPU memory and objects that use a shallow copy with a data pointer in GPU memory (like the YAKL Array class or the Kokkos View class).</p>
<p>Keep in mind this is still very much a work in progress and is ultimately just a stopgap to easily test new architectures until they are fully implemented in the more mature, feature-rich, and performant portability implementations.</p>
<h2>Simple Code Sample</h2>
<p>The following loop would be ported to general accelerators with YAKL as follows:</p>
<div class="fragment"><div class="line">{C++}</div><div class="line">#include &quot;Array.h&quot;</div><div class="line">#include &quot;YAKL.h&quot;</div><div class="line">#include &lt;iostream&gt;</div><div class="line">typedef float real;</div><div class="line">typedef yakl::Array&lt;real,yakl::memHost&gt; realArr;</div><div class="line">inline void applyTendencies(realArr &amp;state2, real const c0, realArr const &amp;state0,</div><div class="line">                                             real const c1, realArr const &amp;state1,</div><div class="line">                                             real const ct, realArr const &amp;tend,</div><div class="line">                                             Domain const &amp;dom) {</div><div class="line">  real tot = 0;</div><div class="line">  for (int l=0; l&lt;numState; l++) {</div><div class="line">    for (int k=0; k&lt;dom.nz; k++) {</div><div class="line">      for (int j=0; j&lt;dom.ny; j++) {</div><div class="line">        for (int i=0; i&lt;dom.nx; i++) {</div><div class="line">          state2(l,hs+k,hs+j,hs+i) = c0 * state0(l,hs+k,hs+j,hs+i) +</div><div class="line">                                     c1 * state1(l,hs+k,hs+j,hs+i) +</div><div class="line">                                     ct * dom.dt * tend(l,k,j,i);</div><div class="line">          tot += state2(l,hs+k,hs+j,hs+i);</div><div class="line">        }</div><div class="line">      }</div><div class="line">    }</div><div class="line">  }</div><div class="line">}</div><div class="line">std::cout &lt;&lt; state2;</div><div class="line">std::cout &lt;&lt; tot &lt;&lt; std::endl;</div></div><!-- fragment --><p>will become:</p>
<div class="fragment"><div class="line">{C++}</div><div class="line">#include &quot;Array.h&quot;</div><div class="line">#include &quot;YAKL.h&quot;</div><div class="line">#include &lt;iostream&gt;</div><div class="line">typedef float real;</div><div class="line">typedef yakl::Array&lt;real,yakl::memDevice&gt; realArr;</div><div class="line">inline void applyTendencies(realArr &amp;state2, real const c0, realArr const &amp;state0,</div><div class="line">                                             real const c1, realArr const &amp;state1,</div><div class="line">                                             real const ct, realArr const &amp;tend,</div><div class="line">                                             Domain const &amp;dom) {</div><div class="line">  // for (int l=0; l&lt;numState; l++) {</div><div class="line">  //   for (int k=0; k&lt;dom.nz; k++) {</div><div class="line">  //     for (int j=0; j&lt;dom.ny; j++) {</div><div class="line">  //       for (int i=0; i&lt;dom.nx; i++) {</div><div class="line">  yakl::parallel_for( numState , dom.nz , dom.ny , dom.nx , YAKL_LAMBDA (int l, int k, int j, int i) {</div><div class="line">    state2(l,hs+k,hs+j,hs+i) = c0 * state0(l,hs+k,hs+j,hs+i) +</div><div class="line">                               c1 * state1(l,hs+k,hs+j,hs+i) +</div><div class="line">                               ct * dom.dt * tend(l,k,j,i);</div><div class="line">  }); </div><div class="line">}</div><div class="line">yakl::ParallelSum&lt;real,yakl::memDevice&gt; psum( numState*dom.nx*dom.ny*dom.nz );</div><div class="line">real tot = psum( state2.data() );</div><div class="line">std::cout &lt;&lt; state2.createHostCopy();</div><div class="line">std::cout &lt;&lt; tot &lt;&lt; std::endl;</div></div><!-- fragment --><h2>Using YAKL</h2>
<p>If you want to use the YAKL Array class, you'll need to <code>#include "Array.h"</code>, and if you want to use the YAKL launchers, you'll need to <code>#include <a class="el" href="YAKL_8h.html">YAKL.h</a></code>. Preface functions you want to run on the accelerator with <code>YAKL_INLINE</code>, and preface lambdas you're passing to YAKL launchers with <code>YAKL_LAMBDA</code> (which does a capture by value for CUDA and HIP backends for Nvidia and AMD hardware, respectively). The <code>parallel_for</code> launcher is used as follows:</p>
<div class="fragment"><div class="line">{C++}</div><div class="line">// for (int i=0; i&lt;nThreads; i++) {</div><div class="line">yakl::parallel_for( int nThreads , FunctorType &amp;f );</div><div class="line"></div><div class="line">// for (int i1=0; i1&lt;n1; i1++) {</div><div class="line">//   for (int i2=0; i2&lt;n2; i2++) {</div><div class="line">yakl::parallel_for( int n1 , int n2 , ... , YAKL_LAMBDA (int i1 , int i2);</div></div><!-- fragment --><p>The <code>Array</code> class is set up to handle two different memories: Host and Device, and you can seen an example of how to use these above as well as in the <a href="https://github.com/mrnorman/awflCloud">awflCloud</a> codebase. Also, it uses C-style index ordering with no padding between elements.</p>
<p>Be sure to use <code><a class="el" href="namespaceyakl.html#afac5fb2f9440a6d7ee378941d8d58daa">yakl::init()</a></code> at the beginning of the program and <code><a class="el" href="namespaceyakl.html#ab42370df4914644cfd129ff6037c5c9f">yakl::finalize()</a></code> at the end.</p>
<h2>Compiling with YAKL</h2>
<p>You currently have three choices for a device backend: HIP, CUDA, and serial CPU. To use different hardware backends, add the following CPP defines in your code. You may only use one.</p>
<table class="doxtable">
<tr>
<th>Hardware </th><th>CPP Flag  </th></tr>
<tr>
<td>AMD GPU </td><td><code>-D__USE_HIP__</code> </td></tr>
<tr>
<td>Nvidia GPU </td><td><code>-D__USE_CUDA__</code> </td></tr>
<tr>
<td>CPU Serial </td><td>no flag </td></tr>
</table>
<p>To turn on array bounds checking, add <code>-DARRAY_DEBUG</code> to your compiler flags.</p>
<p>In your compile line, you'll need to include the YAKL source directory in your <code>CXX_FLAGS</code> (e.g., <code>-I $YAKL_ROOT</code>). Also, you need to add <code>$YAKL_ROOT/YAKL.cpp</code> to your list of source files and its corresponding object file to your list of object files.</p>
<h2>Handling Two Memory Spaces</h2>
<p>The intent of YAKL is to mirror copies of the <code>Array</code> class between two distinct memory spaces: Host (i.e., main memory) and Device (e.g., GPU memory). There are currently four member functions of the <code>Array</code> class to help with data movement:</p>
<div class="fragment"><div class="line">{C++}</div><div class="line">// Create a copy of this Array class in Host Memory, and pass that copy back as a return value.</div><div class="line">template&lt;class T&gt; Array&lt;T,yakl::memHost&gt; createHostCopy();</div><div class="line"></div><div class="line">// Create a copy of this Array class in Device Memory, and pass that copy back as a return value.</div><div class="line">template&lt;class T&gt; Array&lt;T,yakl::memDevice&gt; createDeviceCopy();</div><div class="line"></div><div class="line">// Copy the data from this Array pointer to the Host Array&#39;s pointer (Host Array must already exist)</div><div class="line">template&lt;class T&gt; void deep_copy_to(Array&lt;T,memHost&gt; lhs);</div><div class="line"></div><div class="line">// Copy the data from this Array pointer to the Device Array&#39;s pointer (Device Array must already exist)</div><div class="line">template&lt;class T&gt; void deep_copy_to(Array&lt;T,memDevice&gt; lhs);</div></div><!-- fragment --><p>I plan to change this to something closer to Kokkos's syntax at some point because it's odd to have the lhs be effectively on the rhs like I have it currently.</p>
<h2>Array Reductions</h2>
<p>YAKL provides efficient min, max, and sum array reductions using <a href="https://nvlabs.github.io/cub/">CUB</a> and <a href="https://github.com/ROCmSoftwarePlatform/hipCUB">hipCUB</a> for Nvidia and AMD GPUs. Because these implementations require temporary storage, a design choice was made to expose reductions through class objects. Upon construction, you must specify the size (number of elements to reduce), type (<code>template &lt;class T&gt;</code>) of the array that will be reduced, and the memory space (via template parameter, <code><a class="el" href="namespaceyakl.html#aae8a8c910fec7cef7db68c9658c16405">yakl::memHost</a></code> or <code><a class="el" href="namespaceyakl.html#ac3c32aec58c61e7f870081477ceee883">yakl::memDevice</a></code>) of the array to be reduced. The constructor then allocates memory for the temporary storage. Then, you run the reduction on an array of that size using <code>T operator()(T *data)</code>, which returns the result of the reduction in host memory. When the object goes out of scope, it deallocates the data for you. The array reduction objects are not sharable and implements no shallow copy. An example reduction is below:</p>
<div class="fragment"><div class="line">{C++}</div><div class="line">Array&lt;real&gt; dt3d;</div><div class="line">// Fill dt3d</div><div class="line">yakl::ParallelMin&lt;real,yakl::memDevice&gt; pmin( nx*ny*nz );</div><div class="line">dt = pmin( dt3d.data() );</div></div><!-- fragment --><p>If you want to avoid copying the result back to the host, you can run the <code>void deviceReduce(T *data, T *rslt)</code> member function, where the <code>rslt</code> pointer is allocated in device memory. An example is below:</p>
<div class="fragment"><div class="line">{C++}</div><div class="line">Array&lt;real&gt; dt3d;</div><div class="line">T *dtDev;</div><div class="line">// Allocate dtDev on device</div><div class="line">// Fill dt3d</div><div class="line">yakl::ParallelMin&lt;real,yakl::memDevice&gt; pmin( nx*ny*nz );</div><div class="line">pmin.deviceReduce( dt3d.data() , dtDev );</div></div><!-- fragment --><h2>Asynchronicity</h2>
<p>All YAKL calls are asynchronously launched in the "default" CUDA or HIP stream when run on the device. Array <code>deep_copy_to</code> calls also do the same. With the exception of the reduction <code>operator()</code>, you'll need to call <code><a class="el" href="namespaceyakl.html#a5debd8fe5fff4f37c06e55648d138e0c">yakl::fence()</a></code> if you want to wait on the device operation to complete.</p>
<h2>Future Work</h2>
<p>Plans for the future include:</p><ul>
<li>Adding <a href="https://www.khronos.org/opencl/">OpenCL</a> and <a href="https://www.openmp.org/">OpenMP</a> backends</li>
<li>Adding atomic functions for min, max, and sum</li>
<li>Improving the documentation and testing of YAKL</li>
</ul>
<h2>Software Dependencies</h2>
<p>All of these are included as submodules in this repo:</p><ul>
<li>For Nvidia GPUs, you'll need to clone <a href="https://nvlabs.github.io/cub/">CUB</a></li>
<li>For AMD GPUs, you'll need to clone:<ul>
<li><a href="https://github.com/ROCmSoftwarePlatform/hipCUB">hipCUB</a></li>
<li><a href="https://github.com/ROCmSoftwarePlatform/rocPRIM">rocPIRM</a> </li>
</ul>
</li>
</ul>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
